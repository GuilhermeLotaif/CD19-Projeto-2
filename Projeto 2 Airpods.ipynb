{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;                        Projeto 2 - Ci√™ncia dos Dados\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;                 Alexandre Cury, Guilherme Lotaif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Problema: Classificador autom√°tico de sentimento\n",
    "<br>\n",
    "\n",
    "O Classificador que este projeto ter√° como base √© o Naive-Bayes, que essencialmente ir√° determinar se um peda√ßo de texto √© relevante ou n√£o a um assunto especifico. Iremos trabalhar com posts coletados da rede social Twitter, em forma de tweets, estes ser√£o divididos em dois grupos: Treinamento e teste, para que possamos fazer com que nosso classificador apreenda como discernir o conteudo dos tweets.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:\n",
    "\n",
    "Para fazer uma an√°lise e classifica√ß√£o dos nossos dados, precisamos primeiro coletar os tweets do assunto escolhido em um arquivo excel, que ser√° usado como nossa base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas necess√°rias:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import tweepy\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "#import nltk\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticando no  Twitter\n",
    "\n",
    "Tendo em vista que precisamos da permiss√£o do twitter para acessar e coletar os tweets, √© necess√°rio ter uma conta de desenvolvedor, al√©m de solicitar as chaves de acesso. Para conseguir estas, acompanhe o [tutorial](https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens.html) o pr√≥prio twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Dados de autentica√ß√£o do twitter:\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha do produto e coleta das mensagens\n",
    "\n",
    "Agora √© feita a sele√ß√£o do produto que iremos an√°lisar, e para coletar os tweets para o nosso projeto, √© preciso especificar a quantidade de posts que ser√£o importados `(quanto maior esta quantidade for, mais preciso ser√° o nosso classificador)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido:\n",
    "produto = 'Airpods'\n",
    "#Quantidade m√≠nima de mensagens capturadas:\n",
    "n = 1000\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento:\n",
    "t = 750\n",
    "#Filtro de l√≠ngua, escolha uma na tabela ISO 639-1:\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Capturando os dados do twitter:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura:\n",
    "api = tweepy.API(auth)\n",
    "#Inicia a captura, para mais detalhes: ver a documenta√ß√£o do tweepy:\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower())\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s:\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salvando os dados em uma planilha Excel:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "### Importando e limpando os tweets\n",
    "\n",
    "Esta etapa √© muito importante, porque a maioria dos posts acabam saindo com muita \"sujeira\", esta pode ser desde v√≠rgulas at√© par√™nteses, que podem atrapalhar o classificador. Outra ferramenta de limpeza que usaremos ser√° para manter somente o radical da palavra, assim vamos diminuir a varia√ß√£o de palavras com o mesmo radical mas complementos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abrindo o arquivo:**<br>\n",
    "Este j√° possui uma classifica√ß√£o feita manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo o arquivo de treinamento com os tweets a uma vari√°vel:\n",
    "df_train = pd.read_excel('Airpod.xlsx',0)\n",
    "#Atribuindo o arquivo de teste com os tweets a uma vari√°vel:\n",
    "df_test = pd.read_excel('Airpod.xlsx',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>B1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>rt @itsghibli: spirited away airpod case üíû‚òÅÔ∏è h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>left airpod in hers, right in his, inside targ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  B1\n",
       "226  rt @itsghibli: spirited away airpod case üíû‚òÅÔ∏è h...   0\n",
       "201  left airpod in hers, right in his, inside targ...   1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostrando uma amostra de um dos dataframes:\n",
    "df_train.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Vamos remover a coluna de compara√ß√£o:\n",
    "\n",
    "Para conseguirmos medir a compet√™ncia do nosso classificador, foi feita manualmente uma coluna extra com a relev√¢ncia de cada tweet, que sera usada para comparar os resultados obtidos no final deste projeto. Por√©m ela precisa ser removida para que possamos analisar somente o conteudo dos posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo a coluna \"B1\" do dataframe de treino:\n",
    "df_train_1 = df_train.drop('B1',axis=1)\n",
    "#Removendo a coluna \"B1\" do dataframe de teste:\n",
    "df_test_1 = df_test.drop('B1',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "#### Vamos criar uma fun√ß√£o para a limpeza dos tweets:\n",
    "\n",
    "Esta fun√ß√£o ser√° usada mais para frente, ao separarmos os tweets em duas categorias diferentes: Relevantes e Irrelevantes, com o intuito de limpar as frases de cada post e e separar as palavras, para facilitar que o classificador apreenda as distinguir os dois tipos de tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar uma fun√ß√£o que ir√° substituir os caracteres que trapalham o classificador:\n",
    "def Cleaner (Tweets):\n",
    "    #Os elementos na primeira posi√ß√£o do replace ser√£o substituidos por espa√ßos:\n",
    "    Tweets = Tweets.replace(\"*\",\"\")\n",
    "    Tweets = Tweets.replace(\"!\",\"\")\n",
    "    Tweets = Tweets.replace(\"@\",\"\")\n",
    "    Tweets = Tweets.replace(\"#\",\"\")\n",
    "    Tweets = Tweets.replace(\".\",\"\")\n",
    "    Tweets = Tweets.replace(\":\",\"\")\n",
    "    Tweets = Tweets.replace(\")\",\"\")\n",
    "    Tweets = Tweets.replace(\"(\",\"\")\n",
    "    Tweets = Tweets.replace(\"/\",\"\")\n",
    "    Tweets = Tweets.replace('\"',\"\")\n",
    "    Tweets = Tweets.replace(\"[\",\"\")\n",
    "    Tweets = Tweets.replace(']',\"\")\n",
    "    Tweets = Tweets.replace(\"\\ \",\"\")\n",
    "    Tweets = Tweets.replace(\"rt\",\"\")\n",
    "    Tweets = Tweets.replace(\"&\",\"\")\n",
    "    Tweets = Tweets.replace(\"-\",\"\")\n",
    "    Tweets = Tweets.replace(\"_\",\"\")\n",
    "    Tweets = Tweets.replace(\"+\",\"\")\n",
    "    Tweets = Tweets.replace(\"=\",\"\")\n",
    "    Tweets = Tweets.replace(\"'\",\"\")\n",
    "    Tweets = Tweets.replace(\"?\",\"\")\n",
    "    Tweets = Tweets.replace(\",\",\"\")\n",
    "    \n",
    "    #Vamos retirar os links:\n",
    "    for Word in Tweets:\n",
    "        if 'https' in Word:\n",
    "            Tweets.remove(Word)\n",
    "    \n",
    "    #---------------------------------------------------------------\n",
    "    #Utiliza√ß√£o do stemmer de palavras: que elimina os complementos e deixa somente o radical das palavras\n",
    "    \n",
    "    Post = word_tokenize(Tweets) \n",
    "    Tweets_steam = [ps.stem(word) for word in Post]\n",
    "    #---------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    #Aproveitando a nossa fun√ß√£o ja vamos separar todas as palavras:\n",
    "    Tweets_final = Tweets_steam\n",
    "\n",
    "    return Tweets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "### Separando os Tweets relevantes dos irrelevantes:\n",
    "\n",
    "Para termos mais no√ß√£o se o nosso dataframe possui uma quantidade boa de marcadores da relev√¢ncia dos tweets para \"ensinar\" o classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Descobrindo quantos tweets relevantes o dataframe possui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo a quantidade de tweets relevantes e irrelevantes no dataframe:\n",
    "Relevant, Irrelevant, Really_relevant = (df_train[\"B1\"]).value_counts()\n",
    "#Descobrindo a quantidade total de tweets no dataframe:\n",
    "Total_train = df_train[\"B1\"].value_counts().sum()\n",
    "#Criando uma lista com as informa√ß√µes dos tweets:\n",
    "Tweets_rel_ire_1 =[\"Tweets\", Irrelevant, Relevant, Really_relevant, \"1.00\"]\n",
    "#Criando uma lista com as informa√ß√µes pelo total dos tweets:\n",
    "TOTAL_tweets_1 = [\"TOTAL\", \"{:.2f}\".format(Irrelevant/Total_train), \"{:.2f}\".format(Relevant/Total_train),\n",
    "                  \"{:.2f}\".format(Really_relevant/Total_train), \"1.00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irrelevantes</th>\n",
       "      <th>Relevantes</th>\n",
       "      <th>Muito Relevantes</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tweets</th>\n",
       "      <td>188</td>\n",
       "      <td>233</td>\n",
       "      <td>79</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Irrelevantes Relevantes Muito Relevantes TOTAL\n",
       "                                                     \n",
       "Tweets          188        233               79  1.00\n",
       "TOTAL          0.38       0.47             0.16  1.00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atribuindo os valores √† lista com todos dados:\n",
    "data_rel = [Tweets_rel_ire_1, TOTAL_tweets_1]\n",
    "#Transformando essa lista em um dataframe:\n",
    "data_relevance = (pd.DataFrame(data_rel, columns=[\" \",\"Irrelevantes\",\"Relevantes\",\"Muito Relevantes\",\"TOTAL\"])).set_index(' ')\n",
    "#Plotando os dados:\n",
    "data_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Com a tabela acima conseguimos saber algumas probabilidades quanto aos TWEETS:\n",
    "1. A probabilidade de um tweet ser irrelevante:\n",
    "\n",
    "    $P(Irrelevante)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.60%\n"
     ]
    }
   ],
   "source": [
    "Irrelevant_tot_prob = Irrelevant/Total_train\n",
    "print(\"{:.2f}%\".format((Irrelevant_tot_prob)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A probabilidade de um tweet ser relevante:\n",
    "\n",
    "    $P(Relevante)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.60%\n"
     ]
    }
   ],
   "source": [
    "Relevant_tot_prob = Relevant/Total_train\n",
    "print(\"{:.2f}%\".format((Relevant_tot_prob)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A probabilidade de um tweet ser Muito relevante:\n",
    "\n",
    "    $P(Muito Relevante)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.80%\n"
     ]
    }
   ],
   "source": [
    "Really_relevant_tot_prob = Really_relevant/Total_train\n",
    "print(\"{:.2f}%\".format((Really_relevant_tot_prob)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "<br>\n",
    "\n",
    "\n",
    "Vamos criar um contador para as variaveis relevantes, assim como um dicion√°rio para contar as repeti√ß√µes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar contadores para o total de tweets relevantes e irrelevantes:\n",
    "Really_relevant_count, Relevant_count, Irrelevant_count = 0,0,0\n",
    "#Vamos criar dicion√°rios para os Tweets relevantes e irrelevantes:\n",
    "Really_relevant_dict, Relevant_dict, Irrelevant_dict = {},{},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar um loop para rodar todos os tweets e selecinar s√≥ os irrelevantes:\n",
    "for Tweet in df_train.Treinamento[df_train.B1 == 0]:\n",
    "    #Vamos atribuir todos os tweets irrelevantes √† uma v√°riavel:\n",
    "    Irrelevant_list = Cleaner(Tweet)\n",
    "    #Vamos criar um loop secund√°rio para rodar as palavras de cada tweet:\n",
    "    for Word in Irrelevant_list:\n",
    "        if Word in Irrelevant_dict:\n",
    "            Irrelevant_count += 1\n",
    "            Irrelevant_dict[Word] += 1\n",
    "        else:\n",
    "            Irrelevant_count += 1\n",
    "            Irrelevant_dict[Word] = 1\n",
    "\n",
    "#Vamos criar um loop para rodar todos os tweets e selecinar s√≥ os relevantes:\n",
    "for Tweet in df_train.Treinamento[df_train.B1 == 1]:\n",
    "    #Vamos atribuir todos os tweets relevantes √† uma v√°riavel:\n",
    "    Relevant_list = Cleaner(Tweet)\n",
    "    #Vamos criar um loop secund√°rio para rodar as palavras de cada tweet:\n",
    "    for Word in Relevant_list:\n",
    "        if Word in Relevant_dict:\n",
    "            Relevant_count += 1\n",
    "            Relevant_dict[Word] += 1\n",
    "        else:\n",
    "            Relevant_count += 1\n",
    "            Relevant_dict[Word] = 1\n",
    "            \n",
    "#Vamos criar um loop para rodar todos os tweets e selecinar s√≥ os relevantes:\n",
    "for Tweet in df_train.Treinamento[df_train.B1 == 2]:\n",
    "    #Vamos atribuir todos os tweets relevantes √† uma v√°riavel:\n",
    "    Really_relevant_list = Cleaner(Tweet)\n",
    "    #Vamos criar um loop secund√°rio para rodar as palavras de cada tweet:\n",
    "    for Word in Really_relevant_list:\n",
    "        if Word in Really_relevant_dict:\n",
    "            Really_relevant_count += 1\n",
    "            Really_relevant_dict[Word] += 1\n",
    "        else:\n",
    "            Really_relevant_count += 1\n",
    "            Really_relevant_dict[Word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "<br>\n",
    "\n",
    "#### Vamos an√°lisar um pouco os dados obtidos acima:\n",
    "\n",
    "Ja separamos as palavras presentes nos dois tipos de tweets, agora vamos mostrar a compara√ß√£o das caracteristicas dos dois grupos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo a quantidade de palavras repetidas nos tweets relevantes e irrelevantes:\n",
    "Irrelevant_rep, Relevant_rep, Really_relevant_rep = (len(Irrelevant_dict)),(len(Relevant_dict)),(len(Really_relevant_dict))\n",
    "#Atribuindo a quantidade de palavras N√ÉO repetidas nos tweets irrelevantes:\n",
    "Irrelevant_not_rep = (Irrelevant_count-len(Irrelevant_dict))\n",
    "#Atribuindo a quantidade de palavras N√ÉO repetidas nos tweets relevantes e muito relevantes:\n",
    "Relevant_not_rep, Really_relevant_not_rep = (Relevant_count-len(Relevant_dict)),(Really_relevant_count-len(Really_relevant_dict))\n",
    "#Descobrindo a quantidade total de palavras nos tweets:\n",
    "Words_total = Really_relevant_count + Relevant_count + Irrelevant_count\n",
    "#Vamos criar uma lista para atribuir os valores das palavras com repeti√ß√£o:\n",
    "Words_repetition = [\" Presen√ßa de Repeti√ß√µes\", Irrelevant_rep, Relevant_rep, Really_relevant_rep ,\n",
    "                    \"{:.2f}\".format((Irrelevant_rep+Relevant_rep+Really_relevant_rep)/Words_total)]\n",
    "#Vamos criar uma lista para atribuir os valores das palavras sem repeti√ß√£o:\n",
    "Words_not_repetition = [\"Aus√™ncia de Repeti√ß√µes\", Irrelevant_not_rep, Relevant_not_rep, Really_relevant_not_rep,\n",
    "                        \"{:.2f}\".format((Irrelevant_not_rep+Relevant_not_rep+Really_relevant_not_rep)/Words_total)]\n",
    "#Vamos criar uma lista para atribuir os valores das palavras pelo total:\n",
    "TOTAL_tweets_2 = [\"TOTAL\", \"{:.2f}\".format((Irrelevant_not_rep+Irrelevant_rep)/Words_total),\n",
    "                  \"{:.2f}\".format((Relevant_not_rep+Relevant_rep)/Words_total),\n",
    "                  \"{:.2f}\".format((Really_relevant_not_rep+Really_relevant_rep)/Words_total),\"1.00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irrelevantes</th>\n",
       "      <th>Relevantes</th>\n",
       "      <th>Muito Relevantes</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palavras</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Presen√ßa de Repeti√ß√µes</th>\n",
       "      <td>243</td>\n",
       "      <td>1068</td>\n",
       "      <td>534</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aus√™ncia de Repeti√ß√µes</th>\n",
       "      <td>1341</td>\n",
       "      <td>2750</td>\n",
       "      <td>850</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Irrelevantes Relevantes Muito Relevantes TOTAL\n",
       "Palavras                                                              \n",
       " Presen√ßa de Repeti√ß√µes          243       1068              534  0.27\n",
       "Aus√™ncia de Repeti√ß√µes          1341       2750              850  0.73\n",
       "TOTAL                           0.23       0.56             0.20  1.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Atribuindo os valores √† lista com todos dados:\n",
    "data_rel = [Words_repetition, Words_not_repetition, TOTAL_tweets_2]\n",
    "#Transformando essa lista em um dataframe:\n",
    "data_relevance = (pd.DataFrame(data_rel, columns=[\"Palavras\",\"Irrelevantes\",\"Relevantes\",\"Muito Relevantes\",\n",
    "                                                  \"TOTAL\"])).set_index('Palavras')\n",
    "#Plotando os dados:\n",
    "data_relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "<br>\n",
    "\n",
    "**Um pouco sobre a funcionalidade de um classificador:** A partir dos dados de treinamento, o classificador \"apreende\" quais palavras s√£o mais prov√°veis de acontecer em tal n√≠vel de relev√¢ncia. Portanto, quando usamos os dados de teste para comprovar, mais tarde, podemos perceber que podem haver certas inconsistencias, devido ao fato da nosa base de tweets ser pequena, e que o classificador analisa cada palavra de maneira indiv√≠dual.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "**Agora vamos usar o classificador:** \n",
    "\n",
    "<br>\n",
    "Mostrando como lidar com probabilidade condicional atrav√©s do Teorema de Bayes:\n",
    "\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$$\n",
    "<br>\n",
    "Se substituirmos as devidas vari√°veis, para adequar ao nosso problema:\n",
    "\n",
    "- `Para sabermos a probabilidade de ser relevantes`<br>\n",
    "$$P(RELEVANTE|Tweet) = \\frac{P(Tweet|RELEVANTE) \\cdot P(RELEVANTE)}{P(Tweet)}$$\n",
    "<br>\n",
    "<br>\n",
    "- `Para sabermos a probabilidade de ser irrelevantes`\n",
    "$$P(IRRELEVANTE|Tweet) = \\frac{P(Tweet|IRRELEVANTE) \\cdot P(IRRELEVANTE)}{P(Tweet)}$$\n",
    "<br>\n",
    "\n",
    "Com o objetivo de descobrir se √© relevante ou n√£o, √© cabivel dividir um pelo outro:<br>\n",
    "<br>\n",
    "\n",
    "$$\\frac {P(RELEVANTE|Tweet)}{P(IRRELEVANTE|Tweet)}=\\frac {P(Tweet|RELEVANTE)\\cdot P(RELEVANTE)}{P(Tweet|IRRELEVANTE)\\cdot P(RELEVANTE)}$$<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "<br><br>\n",
    "\n",
    "Abaixo vamos fazer uma fun√ß√£o que nos permitir√° calcular quantas vezes cada palavra pertencente ao tweet escolhido pelo usu√°rio aparece em cada dicion√°rio: dos irrelevante, relevantes e dos muito relevantes. apos isso ela faz uma conta da probabilidade do tweet que apareceu seja de ta grupo, uma vez que dividimos a quantidade de repeti√ß√£o pelo total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos elaborar uma fun√ß√£o que vai calcular a probabilidade do Tweet ser relevante ou n√£o:\n",
    "def Probability_estimator(Dictionary, TWEET, Words_quantity, Probability):\n",
    "    #Vamos atribuir todos os tweets limpos √† uma v√°riavel:\n",
    "    ALL_Cleaned_tweet = Cleaner(TWEET)\n",
    "\n",
    "    #Vamos checar as palavras do dicion√°rio e suas repeti√ß√µes atrav√©s de um loop:\n",
    "    for Words in ALL_Cleaned_tweet:\n",
    "\n",
    "        Amount = 1\n",
    "        if Words in Dictionary:\n",
    "            Amount += Dictionary[Words]\n",
    "        Probability += Amount/(Words_quantity + Words_total)\n",
    "\n",
    "    #Retorna a probablidade:\n",
    "    return Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "<br>\n",
    "\n",
    "A fun√ß√£o a seguir ir√° destinguir qual probabilidade √© maior, e vai retornar o resultado que vencer as restri√ß√µes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar uma  fun√ß√£o que vai comparar os resultados e nos dizer qual √© mais prov√°vel:\n",
    "def Probability_Inspector(Irrelevant_prob, Relevant_prob, Really_relevannt_prob):\n",
    "    if Irrelevant_prob > Relevant_prob and Irrelevant_prob > Really_relevant_prob:\n",
    "        return \"IRRELEVANTE\"\n",
    "    \n",
    "    elif Irrelevant_prob < Relevant_prob and Really_relevant_prob < Relevant_prob:\n",
    "        return \"RELEVANTE\"\n",
    "    \n",
    "    elif Irrelevant_prob < Really_relevant_prob and Relevant_prob < Really_relevant_prob:\n",
    "        return \"MUITO RELEVANTE\"\n",
    "    \n",
    "    else:\n",
    "        return \"EM CIMA DO MURO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...\n",
    "\n",
    "<br>\n",
    "\n",
    "**Espa√ßo para inserir o tweet a ser classificado:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's happening: big airpods\n"
     ]
    }
   ],
   "source": [
    "#Vamos pedir um tweet para ser classificado:\n",
    "Tweet_input = input(\"What's happening: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos calcular a probabilidade de ser irrelevante:\n",
    "Irrelevant_prob = Probability_estimator(Irrelevant_dict, Tweet_input, Irrelevant_count, Irrelevant_tot_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos calcular a probabilidade de ser relevante:\n",
    "Relevant_prob = Probability_estimator(Relevant_dict, Tweet_input, Relevant_count, Relevant_tot_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos calcular a probabilidade de ser muito relevante:\n",
    "Really_relevant_prob = Probability_estimator(Really_relevant_dict, Tweet_input, Really_relevant_count, Really_relevant_tot_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos utilizar a fun√ß√£o criada acima para descobrir a classe correta:\n",
    "Final_decision = Probability_Inspector(Irrelevant_prob, Relevant_prob, Really_relevant_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RELEVANTE'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = []\n",
    "\n",
    "for Tweet_msg in df_test[\"B1\"]:\n",
    "    Irrelevant_prob_test = Probability_estimator(Irrelevant_dict, Tweet_input, Irrelevant_count, Irrelevant_tot_prob)\n",
    "    Relevant_prob_test = Probability_estimator(Relevant_dict, Tweet_input, Relevant_count, Relevant_tot_prob)\n",
    "    Really_relevant_prob_test = Probability_estimator(Really_relevant_dict, Tweet_input, Really_relevant_count, Really_relevant_tot_prob)\n",
    "    Results.append(Probability_Inspector(Irrelevant_prob, Relevant_prob, Really_relevant_prob))\n",
    "\n",
    "df_test['Likely'] = Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos criar as vari√°veis para atribuir os valores desejados:\n",
    "Positive_true = 0\n",
    "Positive_false = 0\n",
    "Negative_true = 0\n",
    "Negative_false = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos usar o codigo zip para percorrer:\n",
    "for likely_test, b1_test in zip(df_test[\"Likely\"],df_test[\"B1\"]):\n",
    "    if likely_test == \"MUITO RELEVANTE\" and b1_test == \"MUITO RELEVANTE\":\n",
    "        Positive_true += 1\n",
    "    elif likely_test == \"RELEVANTE\" and b1_test == \"RELEVANTE\":\n",
    "        Positive_true += 1\n",
    "    elif likely_test == \"MUITO RELEVANTE\" and b1_test != \"MUITO RELEVANTE\":\n",
    "        Positive_false += 1\n",
    "    elif likely_test == \"RELEVANTE\" and b1_test != \"RELEVANTE\":\n",
    "        Positive_false += 1\n",
    "    elif likely_test == \"IRRELEVANTE\" and b1_test == \"IRRELEVANTE\":\n",
    "        Negative_true += 1    \n",
    "    else:\n",
    "        Negative_false += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este classificador de relevancia de tweets, est√° de acordo com o teorema de bayes. Como sua base de dados √© pequena e estamos trabalhando com  3 classifica√ß√µes, entao sua eficacea √© pequena, por√©m ele tem um bom potencial.  Uma outra poss√≠vel aplica√ß√£o para o classificador de bayes √© um detector de emails spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias:\n",
    "\n",
    "- https://github.com/GuilhermeLotaif/SPAM/blob/master/Projeto%202/Projeto2%20Layout.ipynb\n",
    "\n",
    "- https://www.geeksforgeeks.org/python-stemming-words-with-nltk/\n",
    "\n",
    "- https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
